{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(list_of_words, sequence_length):\n",
    "    res = []\n",
    "    for i in range(len(list_of_words)-sequence_length):\n",
    "        res.append((list_of_words[i:i+sequence_length],list_of_words[i+sequence_length]))\n",
    "    return res\n",
    "\n",
    "def splitter(database, fraction, num_words):\n",
    "    \n",
    "    training = [x for x in database['tokens']]\n",
    "    labels = [x for x in database['label_tokens']]\n",
    "\n",
    "    X_train = np.array(training[:int(fraction*len(training))])\n",
    "    X_test = np.array(training[int(fraction*len(training)):])\n",
    "\n",
    "    y_train_base = np.array(labels)[:int(fraction*len(labels))]\n",
    "    y_test_base = np.array(labels)[int(fraction*len(labels)):]\n",
    "\n",
    "    y_train = np.zeros((len(y_train_base), num_words), dtype=np.int8)\n",
    "    y_test = np.zeros((len(y_test_base), num_words), dtype=np.int8)\n",
    "\n",
    "    # One hot encoding of labels\n",
    "    for example_index, word_index in enumerate(y_train_base):\n",
    "        y_train[example_index, word_index] = 1\n",
    "\n",
    "    for example_index, word_index in enumerate(y_test_base):\n",
    "        y_test[example_index, word_index] = 1\n",
    "\n",
    "    print(f'The training sequence shape is {X_train.shape}, the training label shape is {y_train.shape}')\n",
    "    print(f'The test sequence shape is {X_test.shape}, the test label shape is  {y_test.shape}')\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416318</th>\n",
       "      <td>[after, him, and, settled, down, but, hardly, ...</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626335</th>\n",
       "      <td>[added, eh, she, said, nothing, to, that, it, ...</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708629</th>\n",
       "      <td>[presence, bowed, silently, and, went, out, th...</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543168</th>\n",
       "      <td>[i, owed, there, was, no, doubt, flattery, in,...</td>\n",
       "      <td>ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85962</th>\n",
       "      <td>[judgment, based, on, what, seemed, a, natural...</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433982</th>\n",
       "      <td>[remembered, because, her, untidy, back, hair,...</td>\n",
       "      <td>face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494117</th>\n",
       "      <td>[him, from, all, directions, burying, him, so,...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220968</th>\n",
       "      <td>[the, edge, of, the, wall, satan, has, come, t...</td>\n",
       "      <td>really</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173165</th>\n",
       "      <td>[separatedifferent, things, i, suppose, so, no...</td>\n",
       "      <td>our</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135856</th>\n",
       "      <td>[felt, himself, into, the, rôle, until, he, ha...</td>\n",
       "      <td>momentsone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sequence       label\n",
       "416318  [after, him, and, settled, down, but, hardly, ...       light\n",
       "626335  [added, eh, she, said, nothing, to, that, it, ...        know\n",
       "708629  [presence, bowed, silently, and, went, out, th...        this\n",
       "543168  [i, owed, there, was, no, doubt, flattery, in,...         ago\n",
       "85962   [judgment, based, on, what, seemed, a, natural...          by\n",
       "433982  [remembered, because, her, untidy, back, hair,...        face\n",
       "494117  [him, from, all, directions, burying, him, so,...          it\n",
       "220968  [the, edge, of, the, wall, satan, has, come, t...      really\n",
       "173165  [separatedifferent, things, i, suppose, so, no...         our\n",
       "135856  [felt, himself, into, the, rôle, until, he, ha...  momentsone"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books= []\n",
    "\n",
    "\n",
    "delims = ' |\\n|\\ufeff|_'\n",
    "punctuation = '.|,|;|:'\n",
    "wrapping = r'\\--(.--?)\\--'\n",
    "sequence_length = 100\n",
    "\n",
    "for i in range(1,11):\n",
    "    with open(f'../Data/ABT/{i}.txt', mode=\"r\", encoding=\"utf-8\") as file:\n",
    "        contents = file.read().lower()\n",
    "        contents = re.sub(r'[^\\w\\s]', '', contents)\n",
    "        contents = re.split(delims, contents)\n",
    "        books.append([x for x in contents if x != ''])\n",
    "\n",
    "for ind, book in enumerate(books):\n",
    "    books[ind] = generate_sequence(book, sequence_length=sequence_length)\n",
    "\n",
    "master = []\n",
    "\n",
    "for book in books:\n",
    "    for sequence in book:\n",
    "        master.append(sequence)\n",
    "\n",
    "master_frame = pd.DataFrame(master, columns=['sequence','label'])\n",
    "master_frame.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>label_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>628528</th>\n",
       "      <td>[were, springs, in, her, feet, and, her, movem...</td>\n",
       "      <td>to</td>\n",
       "      <td>[32, 6681, 7, 19, 246, 2, 19, 967, 72, 5, 2823...</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167537</th>\n",
       "      <td>[own, theories, and, prejudices, might, be, in...</td>\n",
       "      <td>whereas</td>\n",
       "      <td>[79, 3114, 2, 7966, 136, 44, 7, 25, 525, 333, ...</td>\n",
       "      <td>[1581]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494021</th>\n",
       "      <td>[changed, room, plucked, at, the, center, of, ...</td>\n",
       "      <td>burying</td>\n",
       "      <td>[808, 97, 6281, 18, 1, 2131, 3, 10, 145, 115, ...</td>\n",
       "      <td>[5178]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648693</th>\n",
       "      <td>[enduring, quality, in, his, character, led, h...</td>\n",
       "      <td>the</td>\n",
       "      <td>[9913, 938, 7, 10, 889, 446, 17, 9, 8, 59, 237...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52974</th>\n",
       "      <td>[the, heart, of, the, whole, thing, you, ask, ...</td>\n",
       "      <td>the</td>\n",
       "      <td>[1, 145, 3, 1, 160, 155, 21, 551, 268, 11, 29,...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sequence    label  \\\n",
       "628528  [were, springs, in, her, feet, and, her, movem...       to   \n",
       "167537  [own, theories, and, prejudices, might, be, in...  whereas   \n",
       "494021  [changed, room, plucked, at, the, center, of, ...  burying   \n",
       "648693  [enduring, quality, in, his, character, led, h...      the   \n",
       "52974   [the, heart, of, the, whole, thing, you, ask, ...      the   \n",
       "\n",
       "                                                   tokens label_tokens  \n",
       "628528  [32, 6681, 7, 19, 246, 2, 19, 967, 72, 5, 2823...          [5]  \n",
       "167537  [79, 3114, 2, 7966, 136, 44, 7, 25, 525, 333, ...       [1581]  \n",
       "494021  [808, 97, 6281, 18, 1, 2131, 3, 10, 145, 115, ...       [5178]  \n",
       "648693  [9913, 938, 7, 10, 889, 446, 17, 9, 8, 59, 237...          [1]  \n",
       "52974   [1, 145, 3, 1, 160, 155, 21, 551, 268, 11, 29,...          [1]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(lower=False)\n",
    "tokenizer.fit_on_texts(master_frame['sequence'])\n",
    "master_frame['tokens'] = tokenizer.texts_to_sequences(master_frame['sequence'])\n",
    "master_frame['label_tokens'] = tokenizer.texts_to_sequences(master_frame['label'])\n",
    "\n",
    "word_lexicon = tokenizer.word_index\n",
    "word_index = tokenizer.index_word\n",
    "num_words = len(word_lexicon) + 1\n",
    "word_counts = tokenizer.word_counts\n",
    "sorted_counts = dict(sorted(dict(word_counts).items(), key=lambda item: item[1],reverse=True))\n",
    "\n",
    "master_frame.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 300)          7485600   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100, 64)           93440     \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              66048     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24952)             3218808   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,863,896\n",
      "Trainable params: 10,863,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Embedding, LSTM, Dropout, Bidirectional, Dense\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                                filepath='../Data/weights_RNN.h5',\n",
    "                                                save_weights_only=True,\n",
    "                                                monitor='val_accuracy',\n",
    "                                                mode='max',\n",
    "                                                save_best_only=True)\n",
    "\n",
    "LSTM_cells = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 300, input_length=sequence_length))\n",
    "model.add(LSTM(LSTM_cells,return_sequences=True,dropout=0.1))\n",
    "model.add(Bidirectional(LSTM(LSTM_cells,return_sequences=False,dropout=0.1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_words, activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.save('../Data/RNN_model.h5')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training sequence shape is (64737, 100), the training label shape is (64737, 24952)\n",
      "The test sequence shape is (7193, 100), the test label shape is  (7193, 24952)\n",
      "Epoch 1/40\n",
      "40/40 [==============================] - 9s 73ms/step - loss: 9.3041 - accuracy: 0.0578 - val_loss: 7.3190 - val_accuracy: 0.0812\n",
      "Epoch 2/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 7.3435 - accuracy: 0.0695 - val_loss: 7.0413 - val_accuracy: 0.0812\n",
      "Epoch 3/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 7.2183 - accuracy: 0.0688 - val_loss: 6.9024 - val_accuracy: 0.0812\n",
      "Epoch 4/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.9778 - accuracy: 0.0719 - val_loss: 6.8167 - val_accuracy: 0.0812\n",
      "Epoch 5/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 7.0181 - accuracy: 0.0734 - val_loss: 6.7680 - val_accuracy: 0.0812\n",
      "Epoch 6/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.8885 - accuracy: 0.0715 - val_loss: 6.7123 - val_accuracy: 0.0812\n",
      "Epoch 7/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.8773 - accuracy: 0.0691 - val_loss: 6.6440 - val_accuracy: 0.0812\n",
      "Epoch 8/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.7774 - accuracy: 0.0668 - val_loss: 6.6077 - val_accuracy: 0.0812\n",
      "Epoch 9/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.7932 - accuracy: 0.0699 - val_loss: 6.5785 - val_accuracy: 0.0812\n",
      "Epoch 10/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.7163 - accuracy: 0.0734 - val_loss: 6.5673 - val_accuracy: 0.0812\n",
      "Epoch 11/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 6.8085 - accuracy: 0.0668 - val_loss: 6.5603 - val_accuracy: 0.0812\n",
      "Epoch 12/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.7881 - accuracy: 0.0652 - val_loss: 6.5587 - val_accuracy: 0.0812\n",
      "Epoch 13/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.7169 - accuracy: 0.0664 - val_loss: 6.5393 - val_accuracy: 0.0812\n",
      "Epoch 14/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.6833 - accuracy: 0.0680 - val_loss: 6.5128 - val_accuracy: 0.0812\n",
      "Epoch 15/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.7012 - accuracy: 0.0648 - val_loss: 6.4865 - val_accuracy: 0.0812\n",
      "Epoch 16/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.6289 - accuracy: 0.0715 - val_loss: 6.4736 - val_accuracy: 0.0812\n",
      "Epoch 17/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.6542 - accuracy: 0.0793 - val_loss: 6.4587 - val_accuracy: 0.0812\n",
      "Epoch 18/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.7051 - accuracy: 0.0625 - val_loss: 6.4463 - val_accuracy: 0.0812\n",
      "Epoch 19/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.7033 - accuracy: 0.0664 - val_loss: 6.4576 - val_accuracy: 0.0812\n",
      "Epoch 20/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.6449 - accuracy: 0.0676 - val_loss: 6.4479 - val_accuracy: 0.0812\n",
      "Epoch 21/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.6212 - accuracy: 0.0719 - val_loss: 6.4476 - val_accuracy: 0.0812\n",
      "Epoch 22/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.6548 - accuracy: 0.0742 - val_loss: 6.4386 - val_accuracy: 0.0812\n",
      "Epoch 23/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.6752 - accuracy: 0.0637 - val_loss: 6.4343 - val_accuracy: 0.0812\n",
      "Epoch 24/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.5826 - accuracy: 0.0758 - val_loss: 6.4396 - val_accuracy: 0.0812\n",
      "Epoch 25/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.6426 - accuracy: 0.0668 - val_loss: 6.4290 - val_accuracy: 0.0812\n",
      "Epoch 26/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.5777 - accuracy: 0.0660 - val_loss: 6.4293 - val_accuracy: 0.0812\n",
      "Epoch 27/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.5009 - accuracy: 0.0695 - val_loss: 6.4274 - val_accuracy: 0.0812\n",
      "Epoch 28/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.4246 - accuracy: 0.0695 - val_loss: 6.4226 - val_accuracy: 0.0812\n",
      "Epoch 29/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.5218 - accuracy: 0.0680 - val_loss: 6.4231 - val_accuracy: 0.0812\n",
      "Epoch 30/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.4785 - accuracy: 0.0777 - val_loss: 6.4252 - val_accuracy: 0.0812\n",
      "Epoch 31/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.4989 - accuracy: 0.0660 - val_loss: 6.4318 - val_accuracy: 0.0812\n",
      "Epoch 32/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.5264 - accuracy: 0.0695 - val_loss: 6.4130 - val_accuracy: 0.0812\n",
      "Epoch 33/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.3858 - accuracy: 0.0809 - val_loss: 6.3991 - val_accuracy: 0.0812\n",
      "Epoch 34/40\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 6.5380 - accuracy: 0.0633 - val_loss: 6.3976 - val_accuracy: 0.0969\n",
      "Epoch 35/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 6.4285 - accuracy: 0.0758 - val_loss: 6.3972 - val_accuracy: 0.0953\n",
      "Epoch 36/40\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 6.4825 - accuracy: 0.0824 - val_loss: 6.3950 - val_accuracy: 0.1000\n",
      "Epoch 37/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.3791 - accuracy: 0.0871 - val_loss: 6.3838 - val_accuracy: 0.0953\n",
      "Epoch 38/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.3279 - accuracy: 0.0895 - val_loss: 6.3785 - val_accuracy: 0.0984\n",
      "Epoch 39/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 6.3626 - accuracy: 0.0824 - val_loss: 6.3814 - val_accuracy: 0.0938\n",
      "Epoch 40/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.3201 - accuracy: 0.0930 - val_loss: 6.3789 - val_accuracy: 0.0984\n",
      "The training sequence shape is (64737, 100), the training label shape is (64737, 24952)\n",
      "The test sequence shape is (7193, 100), the test label shape is  (7193, 24952)\n",
      "Epoch 1/40\n",
      "40/40 [==============================] - 5s 71ms/step - loss: 7.2005 - accuracy: 0.0551 - val_loss: 7.3105 - val_accuracy: 0.0781\n",
      "Epoch 2/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 7.1679 - accuracy: 0.0633 - val_loss: 7.2120 - val_accuracy: 0.0844\n",
      "Epoch 3/40\n",
      "40/40 [==============================] - 1s 38ms/step - loss: 6.9938 - accuracy: 0.0660 - val_loss: 7.1834 - val_accuracy: 0.0859\n",
      "Epoch 4/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 7.0391 - accuracy: 0.0574 - val_loss: 7.1621 - val_accuracy: 0.0875\n",
      "Epoch 5/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 6.9930 - accuracy: 0.0629 - val_loss: 7.1424 - val_accuracy: 0.0859\n",
      "Epoch 6/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 7.0177 - accuracy: 0.0641 - val_loss: 7.1251 - val_accuracy: 0.0844\n",
      "Epoch 7/40\n",
      "40/40 [==============================] - 1s 38ms/step - loss: 6.9658 - accuracy: 0.0637 - val_loss: 7.1101 - val_accuracy: 0.0844\n",
      "Epoch 8/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.9856 - accuracy: 0.0621 - val_loss: 7.1029 - val_accuracy: 0.0844\n",
      "Epoch 9/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 7.0571 - accuracy: 0.0629 - val_loss: 7.0876 - val_accuracy: 0.0844\n",
      "Epoch 10/40\n",
      "40/40 [==============================] - 1s 38ms/step - loss: 7.0196 - accuracy: 0.0590 - val_loss: 7.0770 - val_accuracy: 0.0859\n",
      "Epoch 11/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.8929 - accuracy: 0.0582 - val_loss: 7.0720 - val_accuracy: 0.0859\n",
      "Epoch 12/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.9325 - accuracy: 0.0633 - val_loss: 7.0661 - val_accuracy: 0.0859\n",
      "Epoch 13/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 6.9674 - accuracy: 0.0488 - val_loss: 7.0530 - val_accuracy: 0.0844\n",
      "Epoch 14/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.9758 - accuracy: 0.0629 - val_loss: 7.0427 - val_accuracy: 0.0844\n",
      "Epoch 15/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 6.9684 - accuracy: 0.0617 - val_loss: 7.0283 - val_accuracy: 0.0859\n",
      "Epoch 16/40\n",
      "40/40 [==============================] - 1s 38ms/step - loss: 6.8615 - accuracy: 0.0633 - val_loss: 7.0158 - val_accuracy: 0.0859\n",
      "Epoch 17/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 6.9554 - accuracy: 0.0605 - val_loss: 7.0070 - val_accuracy: 0.0859\n",
      "Epoch 18/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.9064 - accuracy: 0.0594 - val_loss: 7.0010 - val_accuracy: 0.0859\n",
      "Epoch 19/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.7905 - accuracy: 0.0594 - val_loss: 6.9940 - val_accuracy: 0.0844\n",
      "Epoch 20/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.9439 - accuracy: 0.0562 - val_loss: 6.9855 - val_accuracy: 0.0859\n",
      "Epoch 21/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.8050 - accuracy: 0.0598 - val_loss: 6.9969 - val_accuracy: 0.0844\n",
      "Epoch 22/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.8823 - accuracy: 0.0641 - val_loss: 6.9836 - val_accuracy: 0.0844\n",
      "Epoch 23/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 6.8658 - accuracy: 0.0605 - val_loss: 6.9734 - val_accuracy: 0.0859\n",
      "Epoch 24/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 6.8207 - accuracy: 0.0527 - val_loss: 6.9639 - val_accuracy: 0.0844\n",
      "Epoch 25/40\n",
      "40/40 [==============================] - 1s 38ms/step - loss: 6.9060 - accuracy: 0.0539 - val_loss: 6.9616 - val_accuracy: 0.0875\n",
      "Epoch 26/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.7682 - accuracy: 0.0577 - val_loss: 6.9577 - val_accuracy: 0.0875\n",
      "Epoch 27/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.6344 - accuracy: 0.0684 - val_loss: 6.9528 - val_accuracy: 0.0891\n",
      "Epoch 28/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.6158 - accuracy: 0.0684 - val_loss: 6.9578 - val_accuracy: 0.0875\n",
      "Epoch 29/40\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 6.7318 - accuracy: 0.0660 - val_loss: 6.9561 - val_accuracy: 0.0875\n",
      "Epoch 30/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 6.6806 - accuracy: 0.0605 - val_loss: 6.9598 - val_accuracy: 0.0875\n",
      "Epoch 31/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 6.6619 - accuracy: 0.0629 - val_loss: 6.9615 - val_accuracy: 0.0906\n",
      "Epoch 32/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.7463 - accuracy: 0.0562 - val_loss: 6.9564 - val_accuracy: 0.0891\n",
      "Epoch 33/40\n",
      "40/40 [==============================] - 1s 38ms/step - loss: 6.6989 - accuracy: 0.0672 - val_loss: 6.9318 - val_accuracy: 0.0875\n",
      "Epoch 34/40\n",
      "40/40 [==============================] - 1s 38ms/step - loss: 6.6372 - accuracy: 0.0621 - val_loss: 6.9419 - val_accuracy: 0.0766\n",
      "Epoch 35/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.6640 - accuracy: 0.0633 - val_loss: 6.9367 - val_accuracy: 0.0891\n",
      "Epoch 36/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.5576 - accuracy: 0.0668 - val_loss: 6.9329 - val_accuracy: 0.0891\n",
      "Epoch 37/40\n",
      "40/40 [==============================] - 1s 38ms/step - loss: 6.5991 - accuracy: 0.0688 - val_loss: 6.9314 - val_accuracy: 0.0891\n",
      "Epoch 38/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.6963 - accuracy: 0.0645 - val_loss: 6.9303 - val_accuracy: 0.0891\n",
      "Epoch 39/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.6089 - accuracy: 0.0602 - val_loss: 6.9365 - val_accuracy: 0.0875\n",
      "Epoch 40/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 6.5344 - accuracy: 0.0602 - val_loss: 6.9301 - val_accuracy: 0.0906\n",
      "The training sequence shape is (64737, 100), the training label shape is (64737, 24952)\n",
      "The test sequence shape is (7193, 100), the test label shape is  (7193, 24952)\n",
      "Epoch 1/40\n",
      "40/40 [==============================] - 5s 70ms/step - loss: 6.5997 - accuracy: 0.0754 - val_loss: 6.4226 - val_accuracy: 0.0734\n",
      "Epoch 2/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.5566 - accuracy: 0.0652 - val_loss: 6.4141 - val_accuracy: 0.0750\n",
      "Epoch 3/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.6757 - accuracy: 0.0672 - val_loss: 6.4148 - val_accuracy: 0.0703\n",
      "Epoch 4/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.4826 - accuracy: 0.0715 - val_loss: 6.4090 - val_accuracy: 0.0719\n",
      "Epoch 5/40\n",
      "40/40 [==============================] - 1s 38ms/step - loss: 6.6182 - accuracy: 0.0652 - val_loss: 6.4169 - val_accuracy: 0.0750\n",
      "Epoch 6/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.4929 - accuracy: 0.0680 - val_loss: 6.3972 - val_accuracy: 0.0734\n",
      "Epoch 7/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.4344 - accuracy: 0.0711 - val_loss: 6.3894 - val_accuracy: 0.0688\n",
      "Epoch 8/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.5614 - accuracy: 0.0785 - val_loss: 6.3846 - val_accuracy: 0.0719\n",
      "Epoch 9/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.5251 - accuracy: 0.0781 - val_loss: 6.3890 - val_accuracy: 0.0719\n",
      "Epoch 10/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 6.5559 - accuracy: 0.0578 - val_loss: 6.3863 - val_accuracy: 0.0734\n",
      "Epoch 11/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.4647 - accuracy: 0.0727 - val_loss: 6.3815 - val_accuracy: 0.0703\n",
      "Epoch 12/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.4960 - accuracy: 0.0738 - val_loss: 6.3747 - val_accuracy: 0.0750\n",
      "Epoch 13/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.4942 - accuracy: 0.0715 - val_loss: 6.3882 - val_accuracy: 0.0766\n",
      "Epoch 14/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.4898 - accuracy: 0.0734 - val_loss: 6.3767 - val_accuracy: 0.0734\n",
      "Epoch 15/40\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 6.5911 - accuracy: 0.0691 - val_loss: 6.3746 - val_accuracy: 0.0734\n",
      "Epoch 16/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.4671 - accuracy: 0.0691 - val_loss: 6.3728 - val_accuracy: 0.0734\n",
      "Epoch 17/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.5128 - accuracy: 0.0715 - val_loss: 6.3730 - val_accuracy: 0.0797\n",
      "Epoch 18/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.4873 - accuracy: 0.0742 - val_loss: 6.3720 - val_accuracy: 0.0750\n",
      "Epoch 19/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.5438 - accuracy: 0.0746 - val_loss: 6.3747 - val_accuracy: 0.0734\n",
      "Epoch 20/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.6482 - accuracy: 0.0633 - val_loss: 6.3674 - val_accuracy: 0.0734\n",
      "Epoch 21/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.4200 - accuracy: 0.0762 - val_loss: 6.3671 - val_accuracy: 0.0719\n",
      "Epoch 22/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.5387 - accuracy: 0.0699 - val_loss: 6.3661 - val_accuracy: 0.0750\n",
      "Epoch 23/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.4647 - accuracy: 0.0715 - val_loss: 6.3600 - val_accuracy: 0.0734\n",
      "Epoch 24/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.5368 - accuracy: 0.0715 - val_loss: 6.3656 - val_accuracy: 0.0719\n",
      "Epoch 25/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.4605 - accuracy: 0.0715 - val_loss: 6.3565 - val_accuracy: 0.0750\n",
      "Epoch 26/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.3552 - accuracy: 0.0771 - val_loss: 6.3479 - val_accuracy: 0.0766\n",
      "Epoch 27/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 6.2560 - accuracy: 0.0859 - val_loss: 6.3410 - val_accuracy: 0.0734\n",
      "Epoch 28/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 6.3940 - accuracy: 0.0719 - val_loss: 6.3468 - val_accuracy: 0.0672\n",
      "Epoch 29/40\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 6.2909 - accuracy: 0.0789 - val_loss: 6.3406 - val_accuracy: 0.0703\n",
      "Epoch 30/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.3219 - accuracy: 0.0781 - val_loss: 6.3389 - val_accuracy: 0.0703\n",
      "Epoch 31/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.3071 - accuracy: 0.0824 - val_loss: 6.3372 - val_accuracy: 0.0656\n",
      "Epoch 32/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.3258 - accuracy: 0.0777 - val_loss: 6.3489 - val_accuracy: 0.0688\n",
      "Epoch 33/40\n",
      "40/40 [==============================] - 1s 38ms/step - loss: 6.3371 - accuracy: 0.0801 - val_loss: 6.3437 - val_accuracy: 0.0734\n",
      "Epoch 34/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.3571 - accuracy: 0.0734 - val_loss: 6.3497 - val_accuracy: 0.0750\n",
      "Epoch 35/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.3287 - accuracy: 0.0715 - val_loss: 6.3453 - val_accuracy: 0.0828\n",
      "Epoch 36/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.4076 - accuracy: 0.0832 - val_loss: 6.3485 - val_accuracy: 0.0828\n",
      "Epoch 37/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.4035 - accuracy: 0.0773 - val_loss: 6.3540 - val_accuracy: 0.0906\n",
      "Epoch 38/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.3796 - accuracy: 0.0805 - val_loss: 6.3548 - val_accuracy: 0.0844\n",
      "Epoch 39/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.2614 - accuracy: 0.0785 - val_loss: 6.3464 - val_accuracy: 0.0828\n",
      "Epoch 40/40\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 6.3099 - accuracy: 0.0793 - val_loss: 6.3504 - val_accuracy: 0.0797\n",
      "The training sequence shape is (64737, 100), the training label shape is (64737, 24952)\n",
      "The test sequence shape is (7193, 100), the test label shape is  (7193, 24952)\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3840/4269665176.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Data/RNN_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         model.fit(X_train, y_train, batch_size=64,\n\u001b[0m\u001b[0;32m     17\u001b[0m                 \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Gaming\\Documents\\Concordia Bootcamp\\Python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Gaming\\Documents\\Concordia Bootcamp\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = 40\n",
    "epochs = 40\n",
    "\n",
    "step = 0.1\n",
    "cut_list = step * np.arange(10)\n",
    "\n",
    "for start, end in zip(cut_list, cut_list+step):\n",
    "    \n",
    "        temp_frame = master_frame.iloc[int(start*len(master_frame)):int(end*len(master_frame))+1]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = splitter(temp_frame,0.9, num_words)\n",
    "\n",
    "        model = load_model('../Data/RNN_model.h5')\n",
    "\n",
    "        model.fit(X_train, y_train, batch_size=64,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=epochs,\n",
    "                callbacks=callback,\n",
    "                validation_data=(X_test,y_test),\n",
    "                validation_steps=10)\n",
    "\n",
    "        del (X_train, X_test, y_train, y_test)\n",
    "\n",
    "        model.save('../Data/RNN_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e17eab0df9e3307548a5c6f41d73e01b4dc6a359441bcee24f0d97b016c3af62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
